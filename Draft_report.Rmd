---
title: "Final Project"
subtitle: "Water Temperature"
author: "Zhanylai Turatkhan kyzy, Julia Kagiliery, Yilun Zhu"
output: pdf_document
geometry: margin=2.54cm
---

```{r, echo=FALSE}
library(ggplot2)
library(readxl)
library(cowplot)
library(tidyverse)
library(lubridate)
library(dplyr)
library(knitr)
library(caret)
library(forecast)
library(zoo)
library(Kendall)
library(tseries)
library(outliers)
library(smooth)
```

**Introduction**


**Motivation/relevance of the study**
Global ocean temperature is on the rise which has significant implications for this dynamic and productive biome. Among the many services the ocean provides, primary production (of oxygen) is among the most impoartant. In fact, approximately 50% of primary production of oxygen comes from marine phytoplankton. It has been proven (largely through work by Duke University Marine Lab's Dr. Zacakry Johnson and Dr. Dana Hunt) that these microbial systems change significantly with seasonal changes (which include dominatntly temperature changes, but also insolation and day length changes). These changes alter the way that the ocean cycles nutrients, stores carbon, and produces oxygen. Hence, temperature is an important variable in the consideration of much ocean modeling. This highlights the imporatnce of acurate temperature prediction. Undertsanding what future climate and temperature looks like allows for better prediction of what other ocean cycles will look like. 

**Objectives**

Our objective is to accurately model the monthly temperature of Piver's Island Coastal Observatory and produce reasonable forecasting at appropriate time scales.

**Dataset Information**
The following data comes from a long running time series study out at Piver's Island Coastal Observatory (PICO) which is located at the Duke University Marine Lab. The sytudy monitors the ambient conditions such as turbidity, pH, temperature, and salinity. For this study, only temperature was able to be included. The temperature is reported as mean monthly temperature. 

```{r, echo=FALSE}
#We important the monthly temperature data
file_path <- "~/WaterTemperature_TSA_FinalProject/Monthly Data_Temperature2011-2021.xlsx"
temperature_data <- read_excel(file_path, sheet = "Sheet1")
```

```{r, echo=FALSE}
#Transforming the data into a time series which starts in Jan of 2011
temperature_ts <- ts(temperature_data$Temperature,
                     start = c(2011, 1), frequency = 12)
```

```{r, echo=FALSE}
#Upon initial examination, the data appears to be strongly seasonal with very little trend.
plot(temperature_ts)
```

```{r}
#The ACF and Pacf tell us that there is ovbious and strong seasonality and some auto-regressive component up to about 6 lags.
P1 <-Acf(temperature_ts)
P2 <- Pacf(temperature_ts)
```

HERE WE SHOULD DECOMPOSE THE DATA.
```{r}
decomposed_Temperature <- decompose(temperature_ts, type = "additive")
plot(decomposed_Temperature)

#Testing if the trend is stationary
MKTest <- MannKendall(temperature_ts)
print(summary(MKTest))

print(adf.test(temperature_ts, alternative = "stationary"))
```

```{r}
#confirming that timeseries transformation works as expected.
str(temperature_ts)
```


In the lines of code below we split the existing data set into a training data set and a test set. 80% of the data is training and the last 20% is used to validate the model.
```{r}
#Making Training and Test sets
split_point <- round(length(temperature_ts) * 0.8)
train_ts <- window(temperature_ts, end=c(2019, 8))
test_ts <- window(temperature_ts, start=c(2019, 9))
```

```{r}
#Confirms Training and Test sets were correctly made
start(train_ts)
end(train_ts)
start(test_ts)
end(test_ts)
```
**Methodology / Analysis**

There are first a few important considerations as we get into modeling. The first is that this data is actually measured approximately weekly, meaning sometimes the lab samples multiple times in a week or skips a week. In order to account for this irregular time series frequency, we aggregated the data into monthly means to avoid unneccesary complications and misalign ment of our time series. 
The second consideration we would like to acknowledge that climate change is certainly a a factor that plays a role in shifting trends, seasonal components, and general variability which may not be accurately reflected in our current data set which spans only approximately 10 years. Though the temperature in the region looks highly predicatble, future predictions must be cognizant that large prediction horizions are unreasonable. 

**Description**
1. SARIMA model
2. Arima+Fourier
3. TBATS model
4. ETS model
5. SSES model
6. Neural Network


*SARIMA Modeling*
```{r, echo=FALSE}
#SARIMA autofit
sarima_model <- auto.arima(train_ts)
print(summary(sarima_model))
```

```{r}
checkresiduals(sarima_model)
```

```{r}
h <- length(test_ts)
sarima_forecast <- forecast(sarima_model, h=h)
```

```{r}
autoplot(temperature_ts, series = "Original") +
  autolayer(sarima_forecast$mean, series = "SARIMA forecast") +
  ylab("Water Temperature") +
  ggtitle("SARIMA modeling")
```

```{r}
checkresiduals(sarima_forecast)
```

```{r}
forecast_accuracySarima <- accuracy(sarima_forecast)
print(forecast_accuracySarima)
```

*ARIMA+fourier Modeling*
```{r ARIMA, echo=TRUE, message=FALSE, warning=FALSE}
ARIMA_Four_fit <- auto.arima(train_ts, 
                             seasonal=TRUE, 
                             lambda=0,
                             xreg=fourier(train_ts, 
                                          K=c(6))
                             )

ARIMA_Four_for <- forecast(ARIMA_Four_fit,
                           xreg=fourier(train_ts,
                                        K=c(6),
                                        h=h),
                           h=h
                           ) 

autoplot(ARIMA_Four_for) + ylab("Temperature")

autoplot(temperature_ts) +
  autolayer(ARIMA_Four_fit$fitted, series="ARIMA_FOURIER Fitted",PI=FALSE) +
  autolayer(ARIMA_Four_for, series="ARIMA_FOURIER Forecast",PI=FALSE) +
  ylab("Temperature")

checkresiduals(ARIMA_Four_for)

forecast_accuracyARIMA_Four <- accuracy(ARIMA_Four_for)
print(forecast_accuracyARIMA_Four)
```

*STL + ETS Modeling*

```{r}
# STL + ETS
ets_model <- stlf(train_ts, h=h)
```

```{r}
ETS_for <- forecast(ets_model, h=h)

autoplot(train_ts) +
    autolayer(ETS_for, series = "ETS Forecast", PI = FALSE) +
  autolayer(fitted(ets_model), series = "Model STL + ETS", PI=FALSE) +
    autolayer(test_ts, series = "Test Data", PI=FALSE) +
  ylab("Water Temperature") +
  ggtitle("STL + ETS modeling")

```

```{r}
stlf_accuracy <- accuracy(ETS_for)
print(stlf_accuracy)
```

```{r}
checkresiduals(ets_model)
```

*TBATS Modeling*

```{r}
model_tbats <- tbats(train_ts)
print(summary(model_tbats))
```

```{r}
checkresiduals(model_tbats)
```


```{r}
TBATS_for <- forecast(model_tbats, h=h)

autoplot(train_ts) +
  autolayer(TBATS_for, series = "TBATS Forecast", PI = FALSE) +
  autolayer(test_ts, series = "Test Data", PI = FALSE) +
  autolayer(fitted(model_tbats), series = "Model", PI = FALSE) +
  ylab("Water Temperature") +
  ggtitle("TBATS Modeling")

```
```{r}
TBATS_accuracy <- accuracy(TBATS_for)
print(TBATS_accuracy)
```

*SSES*
```{r, echo=FALSE}
SSES_seas <- es(train_ts,model="ZZZ", h= h,holdout=FALSE)
plot(SSES_seas)
checkresiduals(SSES_seas)

#Plot model + observed data
autoplot(temperature_ts) +
  autolayer(SSES_seas$fitted, series="SSES Fit",PI=FALSE)+
  autolayer(SSES_seas$forecast, series="SSES Forecast",PI=FALSE)+
  ylab("Temperature") 

forecast_accuracy_SSES <- accuracy(SSES_seas)
```

*Neural Network*
```{r}
NN_fit <- nnetar(train_ts,
                 p=1,
                 P=1,
                 xreg=fourier(train_ts, K=c(6)))

NN_for <- forecast(NN_fit, h= h,xreg=fourier(train_ts, 
                                          K=c(6),h= h))

autoplot(NN_for) +
  ylab("Temperature C") 

autoplot(test_ts) +
  autolayer(NN_for, series="Neural Network",PI=FALSE)+
  ylab("Temperature") 

autoplot(temperature_ts) +
  autolayer(NN_for$fitted, series="NN fit",PI=FALSE) +
  autolayer(NN_for$mean, series="NN forecast",PI=FALSE)+
  ylab("Temperature") 

checkresiduals(NN_fit)

forecast_accuracy_NN <- accuracy(NN_for)
```
*Create Scores*
```{r}

#Model 1: Sarima
Sarima_scores <- accuracy(sarima_forecast$mean, test_ts) 

#Model 2: ARIMA + Fourier
ArimaFour_scores <- accuracy(ARIMA_Four_for$mean, test_ts)  

#Model 3: ETS+STL 
stlf_scores <- accuracy(ETS_for$mean, test_ts)

# Model 4:  TBATS 
TBATS_scores <- accuracy(TBATS_for$mean, test_ts)

# Model 5:  SSES 
SSES_scores <- accuracy(NN_for$mean, test_ts)

# Model 6:  Neural Network 
NN_scores <- accuracy(SSES_seas$forecast, test_ts)

```

*Create Score table*
```{r}
scores <- as.data.frame(
  rbind(Sarima_scores, ArimaFour_scores, stlf_scores, TBATS_scores, SSES_scores, NN_scores)
  )
row.names(scores) <- c("Sarima", "ARIMA+Fourier","ETS+STL","TBATS","SSES", "NN")

best_model_index <- which.min(scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(scores[best_model_index,]))                       
```

