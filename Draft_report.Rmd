---
title: "Final Project"
subtitle: "Water Temperature"
author: "Zhanylai Turatkhan kyzy, Julia Kagiliery, Yilun Zhu"
output: pdf_document
geometry: margin=2.54cm
---


```{r, echo=FALSE}
library(ggplot2)
library(readxl)
library(cowplot)
library(tidyverse)
library(lubridate)
library(dplyr)
library(knitr)
library(caret)
library(forecast)
library(zoo)
library(Kendall)
library(tseries)
library(outliers)
library(smooth)
```


**Introduction**
Marine microbe account for 50% of marine primary production and dominate the 
biomass of the ocean. These organism are vital for life on earth and ocean 
health but are at serious risk in high temperatures worsened by climate change. 
The first step in supporting these ecological communities and hence mitigating 
the damages done by climate change is to understand what future climate 
scenarios look like. Predictions for future climate and temperature can varry by 
up to 10 degrees (if not more). With so much uncertainty surrounding climate 
future, it is of the utmost importance to have as much acurate modeling for 
future climate scenarios and hence our group hopes to make reasonable forecasts 
of surface water temperature at the Duke University Marine Lab research facility.  

**Motivation/relevance of the study**
Global ocean temperature is on the rise which has significant implications for 
this dynamic and productive biome. Among the many services the ocean provides, 
primary production (of oxygen) is among the most important. In fact, 
approximately 50% of primary production of oxygen comes from marine 
phytoplankton. It has been proven (largely through work by Duke University 
Marine Lab's Dr. Zacakry Johnson and Dr. Dana Hunt) that these microbial 
systems change significantly with seasonal changes (which include dominantly 
temperature changes, but also isolation and day length changes). These changes 
alter the way that the ocean cycles nutrients, stores carbon, and produces 
oxygen. Hence, temperature is an important variable in the consideration of much 
ocean modeling. This highlights the importance of accurate temperature 
prediction. Understanding what future climate and temperature looks like allows 
for better prediction of what other ocean cycles will look like and how we may 
excpet the serives we recieve from the ocean to change with the climate. 

**Objectives**

Our objective is to accurately model the monthly temperature of Piver's 
Island Coastal Observatory and produce reasonable forecasting at appropriate 
time scales.

**Dataset Information**

The following data comes from a long running time series study out at Piver's 
Island Coastal Observatory (PICO) which is located at the Duke University 
Marine Lab conducted by Drs. Zackary Johnson and Dana Hunt. The sytudy monitors 
the ambient conditions such as turbidity, pH, temperature, and salinity. For 
this study, only temperature was able to be included. The temperature is 
reported as mean monthly temperature. 

**Methodology / Analysis**

There are first a few important considerations as we get into modeling. The 
first is that this data is actually measured approximately weekly, meaning 
sometimes the lab samples multiple times in a week or skips a week. In order 
to account for this irregular time series frequency, we aggregated the data 
into monthly means to avoid unnecessary complications and misalignment of our 
time series. 
The second consideration we would like to acknowledge that climate change is 
certainly a a factor that plays a role in shifting trends, seasonal components, 
and general variability which may not be accurately reflected in our current 
data set which spans only approximately 11 years. Though the temperature in the 
region looks highly predictable, future predictions must be cognizant that large 
prediction horizons are unreasonable. 

**Description**

**1. SARIMA model:** The Seasonal Autoregressive Integrated Moving Average 
(SARIMA) model expands upon the ARIMA framework to address seasonality in 
univariate data sets. It incorporates both non-seasonal and seasonal elements 
in its predictions, allowing it to capture complex patterns that recur over 
fixed periods.
**2. Arima+Fourier:** This approach combines the ARIMA model with Fourier series 
to enhance the modeling of time series with complex seasonal patterns. 
ARIMA captures the autocorrelations in the data, while the Fourier terms allow 
for the approximation of seasonal cycles of various lengths and complexities. 
This hybrid model is especially useful when the seasonality is not strictly 
periodic or involves multiple frequencies.
**3. TBATS model:** Designed for forecasting time series with intricate seasonal 
patterns, the TBATS model employs exponential smoothing as its core technique. 
It thoroughly explores a variety of specifications, including those with and 
without a Box-Cox transformation, the presence or absence of a trend, trend 
damping options, and an ARIMA(p,q) component for the residuals. The model also 
evaluates different harmonic levels for seasonalities. The best-fitting model 
is determined by the lowest Akaike Information Criterion (AIC).
**4. ETS model:** This univariate forecasting method, known as Exponential 
Smoothing State Space Model (ETS), emphasizes trend and seasonality components 
within the time series data. It is particularly adept at capturing patterns 
that evolve over time.
**5. SSES model:** The State Space Exponential Smoothing (SSES) model extends 
the classic exponential smoothing approach by incorporating distribution 
assumptions about the error terms, which aids in the computation of prediction 
intervals. It considers both additive and multiplicative error structures 
within the state space modeling framework.
**6. Neural Network:** The Neural Network model facilitates the identification 
of complex and nonlinear relationships between the dependent variable and its 
predictors. Its versatile architecture can adapt to a wide array of data 
patterns.

```{r, echo=FALSE}
#file_path <- file.path(getwd(), "Monthly Data_Temperature2011-2021.xlsx")
#print(file_path)
```


```{r, echo=FALSE}
#We important the monthly temperature data
file_path <-
  "~/WaterTemperature_TSA_FinalProject/Monthly Data_Temperature2011-2021.xlsx"
temperature_data <- read_excel(file_path, sheet = "Sheet1")
```

```{r, echo=FALSE}
#Transforming the data into a time series which starts in Jan of 2011
temperature_ts <- ts(temperature_data$Temperature,
                     start = c(2011, 1), frequency = 12)
```

```{r, echo=FALSE}
#Upon initial examination, the data appears to be seasonal with little trend.
plot(temperature_ts, main = "Original dataset")
```
The temperature shows cyclical behavior with peaks and troughs that correspond 
to expected seasonal variations. The amplitude of these oscillations appears 
consistent over the years, indicating a stable seasonal effect without 
significant year-over-year changes in peak or trough temperatures.
From a visual inspection, there are no apparent outliers or disruptions in the 
seasonal pattern, suggesting that the dataset is clean and well-maintained. 
The regularity of the pattern would likely make it suitable for forecasting 
using seasonal models, such as SARIMA or TBATS, which could exploit the 
periodicity inherent in the data.
```{r, echo=FALSE}
#The ACF and Pacf tell us that there is ovbious and strong seasonality and some auto-regressive component up to about 6 lags.
P1 <-Acf(temperature_ts, main = "ACF on original data")
```
The graph illustrates the Autocorrelation Function (ACF) applied to the original 
temperature data set. Autocorrelation is a mathematical representation of the 
degree of similarity between a given time series and a lagged version of itself 
over successive time intervals. The ACF is plotted against various lag values, 
which span from 0 to 24.
The y-axis represents the autocorrelation coefficient, ranging from -0.5 to 0.5, 
while the x-axis represents the lag in terms of the number of time units. Each 
vertical bar corresponds to the autocorrelation coefficient at a specific lag.
Notably, the graph shows a pattern of spikes at regular intervals, which 
suggests a seasonal pattern in the data. The presence of these spikes at 
consistent intervals can be indicative of the seasonality in the dataset, which 
correlates with the seasonal fluctuations seen in the time series plot of 
the original dataset.
The blue dashed lines represent the significance bounds. Any spike that extends 
beyond these bounds is considered statistically significant. In this ACF plot, 
several lags have autocorrelation values that cross the significance threshold,
confirming that the data exhibit a strong seasonal component at these lags.

```{r, echo=FALSE}
P2 <- Pacf(temperature_ts, main = "PACF on original data")
```
In this PACF plot, most of the spikes are within the significance bounds, 
suggesting that most of the autocorrelations in the original data can be 
accounted for by the immediate preceding values.

```{r, echo=FALSE}
decomposed_Temperature <- decompose(temperature_ts, type = "additive")
plot(decomposed_Temperature)

#Testing if the trend is stationary
MKTest <- MannKendall(temperature_ts)
print(summary(MKTest))

print(adf.test(temperature_ts, alternative = "stationary"))
```
The Augmented Dickey-Fuller Test result indicates a Dickey-Fuller statistic of 
-11.153 with a lag order of 5, and a p-value of 0.01, suggesting that the null 
hypothesis of a unit root can be rejected and the time series is stationary.
```{r, echo=FALSE}
#confirming that timeseries transformation works as expected.
str(temperature_ts)
```

For the forecasting purposes, the data was split into training and test data
following a proportion of 80/20.
```{r, echo=FALSE}
#Making Training and Test sets
split_point <- round(length(temperature_ts) * 0.8)
train_ts <- window(temperature_ts, end=c(2019, 8))
test_ts <- window(temperature_ts, start=c(2019, 9))
```

```{r, echo=FALSE}
#Confirms Training and Test sets were correctly made
start(train_ts)
end(train_ts)
start(test_ts)
end(test_ts)
```

*SARIMA Modeling*
```{r, echo=FALSE}
#SARIMA autofit
sarima_model <- auto.arima(train_ts)
print(summary(sarima_model))
```

```{r, echo=FALSE}
checkresiduals(sarima_model)
```

```{r, echo=FALSE}
h <- length(test_ts)
sarima_forecast <- forecast(sarima_model, h=h)
```

```{r, echo=FALSE}
autoplot(temperature_ts, series = "Original") +
  autolayer(sarima_forecast$mean, series = "SARIMA forecast") +
  ylab("Water Temperature") +
  ggtitle("SARIMA modeling")
```

```{r, echo=FALSE}
checkresiduals(sarima_forecast)
```

```{r, echo=FALSE}
forecast_accuracySarima <- accuracy(sarima_forecast)
print(forecast_accuracySarima)
```

*ARIMA+fourier Modeling*
```{r ARIMA, echo=TRUE, message=FALSE, warning=FALSE}
ARIMA_Four_fit <- auto.arima(train_ts, 
                             seasonal=TRUE, 
                             lambda=0,
                             xreg=fourier(train_ts, 
                                          K=c(6))
                             )

ARIMA_Four_for <- forecast(ARIMA_Four_fit,
                           xreg=fourier(train_ts,
                                        K=c(6),
                                        h=h),
                           h=h
                           ) 

autoplot(ARIMA_Four_for) + ylab("Temperature")

autoplot(temperature_ts) +
  autolayer(ARIMA_Four_fit$fitted, series="ARIMA_FOURIER Fitted",PI=FALSE) +
  autolayer(ARIMA_Four_for, series="ARIMA_FOURIER Forecast",PI=FALSE) +
  ylab("Temperature")

checkresiduals(ARIMA_Four_for)

forecast_accuracyARIMA_Four <- accuracy(ARIMA_Four_for)
print(forecast_accuracyARIMA_Four)
```

*STL + ETS Modeling*

```{r, echo=FALSE}
# STL + ETS
ets_model <- stlf(train_ts, h=h)
```

```{r, echo=FALSE}
ETS_for <- forecast(ets_model, h=h)

autoplot(train_ts) +
    autolayer(ETS_for, series = "ETS Forecast", PI = FALSE) +
  autolayer(fitted(ets_model), series = "Model STL + ETS", PI=FALSE) +
    autolayer(test_ts, series = "Test Data", PI=FALSE) +
  ylab("Water Temperature") +
  ggtitle("STL + ETS modeling")

```

```{r, echo=FALSE}
stlf_accuracy <- accuracy(ETS_for)
print(stlf_accuracy)
```

```{r, echo=FALSE}
checkresiduals(ets_model)
```

*TBATS Modeling*

```{r, echo=FALSE}
model_tbats <- tbats(train_ts)
print(summary(model_tbats))
```

```{r, echo=FALSE}
checkresiduals(model_tbats)
```


```{r, echo=FALSE}
TBATS_for <- forecast(model_tbats, h=h)

autoplot(train_ts) +
  autolayer(TBATS_for, series = "TBATS Forecast", PI = FALSE) +
  autolayer(test_ts, series = "Test Data", PI = FALSE) +
  autolayer(fitted(model_tbats), series = "Model", PI = FALSE) +
  ylab("Water Temperature") +
  ggtitle("TBATS Modeling")

```
```{r, echo=FALSE}
TBATS_accuracy <- accuracy(TBATS_for)
print(TBATS_accuracy)
```

*SSES*
```{r, echo=FALSE}
SSES_seas <- es(train_ts,model="ZZZ", h= h,holdout=FALSE)
plot(SSES_seas)
checkresiduals(SSES_seas)

#Plot model + observed data
autoplot(temperature_ts) +
  autolayer(SSES_seas$fitted, series="SSES Fit",PI=FALSE)+
  autolayer(SSES_seas$forecast, series="SSES Forecast",PI=FALSE)+
  ylab("Temperature") 

forecast_accuracy_SSES <- accuracy(SSES_seas)
```

*Neural Network*
```{r, echo=FALSE}
NN_fit <- nnetar(train_ts,
                 p=1,
                 P=1,
                 xreg=fourier(train_ts, K=c(6)))

NN_for <- forecast(NN_fit, h= h,xreg=fourier(train_ts, 
                                          K=c(6),h= h))

autoplot(NN_for) +
  ylab("Temperature C") 

autoplot(test_ts) +
  autolayer(NN_for, series="Neural Network",PI=FALSE)+
  ylab("Temperature") 

autoplot(temperature_ts) +
  autolayer(NN_for$fitted, series="NN fit",PI=FALSE) +
  autolayer(NN_for$mean, series="NN forecast",PI=FALSE)+
  ylab("Temperature") 

checkresiduals(NN_fit)

forecast_accuracy_NN <- accuracy(NN_for)
```
*Create Scores*
```{r, echo=FALSE}

#Model 1: Sarima
Sarima_scores <- accuracy(sarima_forecast$mean, test_ts) 

#Model 2: ARIMA + Fourier
ArimaFour_scores <- accuracy(ARIMA_Four_for$mean, test_ts)  

#Model 3: ETS+STL 
stlf_scores <- accuracy(ETS_for$mean, test_ts)

# Model 4:  TBATS 
TBATS_scores <- accuracy(TBATS_for$mean, test_ts)

# Model 5:  SSES 
SSES_scores <- accuracy(NN_for$mean, test_ts)

# Model 6:  Neural Network 
NN_scores <- accuracy(SSES_seas$forecast, test_ts)

```

*Create Score table*
```{r, echo=FALSE}
scores <- as.data.frame(
  rbind(
    Sarima_scores,
    ArimaFour_scores,
    stlf_scores,
    TBATS_scores,
    SSES_scores,
    NN_scores
  )
)
row.names(scores) <-
  c("Sarima", "ARIMA+Fourier", "ETS+STL", "TBATS", "SSES", "NN")

best_model_index <- which.min(scores[, "RMSE"])
cat("The best model by RMSE is:", row.names(scores[best_model_index, ]))                       
```

**Limitations**
Though we have produced accurate models and forecasts, there are a few limitations to be aware of. The first is regarding our prediction time frame We only have access to ~ 10 years of data which likely does not demonstrate enough of a trend to be recognized as the role of climate change in our models. We should expect increasing temepratures in the future as a result of climate change. Even if our model did capture this linear trend, the modeling would be based on the assumtions that the trend is constant (aka that emissions causing climate change are to remain exactly as they are now, neither increasing nor decreasing). This limits further the time frame for which projections and models are viable. Finally, the resolution of our data is not ideal; we have monthly aggregate data so we are projecting out monthly as well. This is not as helpful as a finer resolution may have been given the fact that monthy aggregate data does not accurately reflect the extreme temeprature spikes we may see on specific days. In the future, it would be usely to repeat this modeling ideally with daily data. Even geting multiple temepratures a day could had more complexity as we should except to see patterns of temeprature changes throughout the day.

**Selected Refrences**
Johnson, Z. I., Wheeler, B. J., Blinebry, S. K., Carlson, C. M., Ward, C., & Hunt, D. E. (2013a). Dramatic variability of the carbonate system at a temperate coastal ocean site (Beaufort, North Carolina, USA) is regulated by physical and biogeochemical processes on multiple timescales. PloS One, 8(12), e85117. https://doi.org/10.1371/journal.pone.0085117

McIntyre, A. D. (2010). Life in the world’s oceans. In Wiley eBooks. https://doi.org/10.1002/9781444325508

Wang, Z., Tsementzi, D., Williams, T. C., Juarez, D. L., Blinebry, S. K., Garcia, N. S., Sienkiewicz, B. K., Konstantinidis, K. T., Johnson, Z. I., & Hunt, D. E. (2020a). Environmental stability impacts the differential sensitivity of marine microbiomes to increases in temperature and acidity. The ISME Journal, 15(1), 19–28. https://doi.org/10.1038/s41396-020-00748-2
